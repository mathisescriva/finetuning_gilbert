# Quick Start : Lancer QAT depuis CLI

## üéØ La Solution la Plus Simple

### Option 1 : RunPod (Recommand√©) ‚≠ê

**1. Cr√©er compte sur https://runpod.io**

**2. Lancer une instance GPU** :
- Template : PyTorch
- GPU : RTX 3090 ou A100 (selon budget)
- Co√ªt : ~$0.20-0.40/h

**3. Se connecter en SSH** et ex√©cuter :

```bash
# Clone votre repo
git clone <votre-repo-url>
cd finetuning_gilbert

# Setup automatique + entra√Ænement
bash setup_and_train.sh
```

**C'est tout !** Le script fait tout automatiquement :
- ‚úÖ Installe d√©pendances
- ‚úÖ T√©l√©charge dataset
- ‚úÖ Lance entra√Ænement QAT (2-4h)

**Co√ªt total : ~$0.80-1.60**

---

### Option 2 : Google Colab (Gratuit/Pro)

**1. Ouvrir https://colab.research.google.com**

**2. Nouveau notebook ‚Üí Runtime ‚Üí Change runtime type ‚Üí GPU**

**3. Ex√©cuter ces cellules** :

```python
# Cellule 1 : Installer d√©pendances
!pip install -q transformers datasets accelerate librosa soundfile jiwer optimum[onnxruntime] torch torchaudio

# Cellule 2 : Cloner repo (ou uploader manuellement)
!git clone <votre-repo-url>
%cd finetuning_gilbert

# Cellule 3 : Setup
!bash setup_and_train.sh
```

**Limite** : 12h max (free) ou illimit√© (Pro $10/mois)

---

### Option 3 : Local (Si GPU disponible)

```bash
# 1. V√©rifier GPU
nvidia-smi

# 2. Lancer setup automatique
bash setup_and_train.sh
```

---

## üìã Commandes CLI Essentielles

### V√©rifier l'environnement

```bash
# V√©rifier Python
python3 --version  # Doit √™tre 3.8+

# V√©rifier GPU
nvidia-smi  # Doit afficher votre GPU

# V√©rifier PyTorch + CUDA
python3 -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
```

### Setup manuel (si script ne fonctionne pas)

```bash
# 1. Installer d√©pendances
pip install -r requirements.txt
pip install optimum[onnxruntime]

# 2. T√©l√©charger dataset
python scripts/download_datasets.py --datasets common_voice --max_samples 60000

# 3. Lancer entra√Ænement
make train-qat-int8
```

### Monitoring pendant l'entra√Ænement

```bash
# Voir les logs
tail -f outputs/logs/trainer_logs.txt

# Ou avec TensorBoard (si install√©)
tensorboard --logdir outputs/logs
```

---

## üêõ Probl√®mes Courants

### "CUDA out of memory"

```bash
# R√©duire batch size
python scripts/train_qat.py \
  --per_device_batch_size 4  # Au lieu de 8
```

### "Module not found"

```bash
# R√©installer d√©pendances
pip install -r requirements.txt --upgrade
```

### Dataset non trouv√©

```bash
# T√©l√©charger manuellement
python scripts/download_datasets.py --datasets common_voice
```

---

## ‚úÖ Apr√®s Entra√Ænement

```bash
# 1. Convertir en quantifi√©
python scripts/convert_qat_to_quantized.py \
  --model_path outputs/models/whisper-qat-int8/final \
  --output_path outputs/models/whisper-qat-int8-quantized \
  --quantization_type int8

# 2. √âvaluer
make evaluate-qat
```

---

## üí° Recommandation

**Pour votre cas** : Utilisez **RunPod** ou **Vast.ai**

- Setup en 5 minutes
- GPU pas cher
- Acc√®s SSH direct
- Script automatique fait tout

**Commande compl√®te** :
```bash
git clone <repo> && cd finetuning_gilbert && bash setup_and_train.sh
```

C'est tout ce qu'il faut ! üöÄ

