# Guide : GÃ©nÃ©ration Automatique de Transcripts

## ğŸ¯ Objectif

Ce guide explique comment gÃ©nÃ©rer automatiquement des transcripts pour un dataset audio qui n'en a pas. Deux approches sont disponibles :

1. **Services commerciaux** (AssemblyAI, Deepgram, etc.) - â­ **RECOMMANDÃ‰** pour meilleure qualitÃ©
2. **Whisper gratuit** - Alternative Ã©conomique mais qualitÃ© moindre

## ğŸ’¡ Pourquoi utiliser un service commercial ?

**Avantages :**
- âœ… **Meilleure qualitÃ©** : Services optimisÃ©s pour production
- âœ… **Plus rapide** : API optimisÃ©es, traitement parallÃ¨le
- âœ… **FonctionnalitÃ©s avancÃ©es** : Diarisation, ponctuation, timestamps
- âœ… **Moins d'erreurs** : Meilleure reconnaissance noms propres, accents

**InconvÃ©nients :**
- âš ï¸ **CoÃ»t** : ~$0.0001-0.001 par minute audio
- âš ï¸ **DÃ©pendance API** : NÃ©cessite connexion internet

**Recommandation** : Pour des pseudo-labels de qualitÃ© maximale (et donc meilleur fine-tuning), utilisez un service commercial si le budget le permet.

## ğŸš€ Utilisation Rapide

### Option 1 : Service Commercial (RECOMMANDÃ‰) â­

**AssemblyAI** (meilleur rapport qualitÃ©/prix) :

```bash
# 1. Obtenir une clÃ© API gratuite (50$ de crÃ©dit) : https://www.assemblyai.com
# 2. DÃ©finir la clÃ©
export ASSEMBLYAI_API_KEY="votre_cle_api"

# 3. GÃ©nÃ©rer transcripts
python scripts/generate_transcripts_commercial.py \
  --dataset_name MEscriva/french-education-speech \
  --service assemblyai \
  --split train
```

**Deepgram** (alternative performante) :

```bash
export DEEPGRAM_API_KEY="votre_cle_api"
python scripts/generate_transcripts_commercial.py \
  --dataset_name MEscriva/french-education-speech \
  --service deepgram
```

### Option 2 : Whisper Gratuit (Alternative)

```bash
# GÃ©nÃ©ration avec Whisper (gratuit mais qualitÃ© moindre)
python scripts/generate_transcripts.py \
  --dataset_name MEscriva/french-education-speech \
  --split train \
  --output_dir data/processed

# Ou avec Makefile
make generate-transcripts
```

## ğŸ“‹ Options DÃ©taillÃ©es

### Commandes de Base

```bash
python scripts/generate_transcripts.py \
  --dataset_name MEscriva/french-education-speech \
  --split train \
  --output_dir data/processed \
  --output_name french_education_with_transcripts
```

### Options Utiles

**Test rapide (limiter le nombre d'Ã©chantillons) :**
```bash
python scripts/generate_transcripts.py \
  --dataset_name MEscriva/french-education-speech \
  --max_samples 10  # Test avec 10 Ã©chantillons seulement
```

**Filtrer par confidence (garder seulement transcripts fiables) :**
```bash
python scripts/generate_transcripts.py \
  --dataset_name MEscriva/french-education-speech \
  --min_confidence 0.7  # Garder seulement confidence >= 0.7
```

**Utiliser un autre modÃ¨le Whisper :**
```bash
python scripts/generate_transcripts.py \
  --dataset_name MEscriva/french-education-speech \
  --model_name openai/whisper-large-v3  # ModÃ¨le plus puissant mais plus lent
```

**Pousser le dataset sur HuggingFace Hub :**
```bash
python scripts/generate_transcripts.py \
  --dataset_name MEscriva/french-education-speech \
  --push_to_hub \
  --hub_token YOUR_TOKEN
```

## ğŸ” Fonctionnement

### Processus

1. **Chargement du dataset** : Le script charge votre dataset depuis HuggingFace
2. **Chargement du modÃ¨le Whisper** : Utilise `bofenghuang/whisper-large-v3-distil-fr-v0.2` par dÃ©faut
3. **Transcription** : Pour chaque audio, gÃ©nÃ¨re un transcript automatique
4. **Calcul de confidence** : Estime la confiance de chaque transcript
5. **Sauvegarde** : CrÃ©e un nouveau dataset avec les transcripts ajoutÃ©s

### Format de Sortie

Le dataset gÃ©nÃ©rÃ© contient :
- **Colonne originale `audio`** : ConservÃ©e
- **Nouvelle colonne `text`** : Transcripts gÃ©nÃ©rÃ©s automatiquement
- **Nouvelle colonne `transcription_confidence`** : Score de confiance (0-1)
- **Nouvelle colonne `auto_generated`** : `True` pour tous les transcripts auto

### Structure de Sortie

```
data/processed/
â””â”€â”€ MEscriva_french-education-speech_with_transcripts/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ dataset_info.json
    â”‚   â””â”€â”€ state.json
    â””â”€â”€ transcripts.json  # Export JSON pour rÃ©fÃ©rence
```

## ğŸ“Š Statistiques et QualitÃ©

### InterprÃ©tation des Scores de Confiance

- **0.8 - 1.0** : TrÃ¨s fiable âœ…
- **0.6 - 0.8** : Fiable âœ…
- **0.4 - 0.6** : Ã€ vÃ©rifier âš ï¸
- **< 0.4** : Faible, probablement erreur âŒ

### Filtrage RecommandÃ©

Pour un fine-tuning de qualitÃ©, filtrez les transcripts de faible confidence :

```bash
# Garder seulement transcripts confiants
python scripts/generate_transcripts.py \
  --dataset_name MEscriva/french-education-speech \
  --min_confidence 0.6
```

## âœ… VÃ©rification et Correction Manuelle (Optionnel)

### Exporter les transcripts pour vÃ©rification

Le script gÃ©nÃ¨re aussi un fichier `transcripts.json` :

```json
[
  {
    "index": 0,
    "text": "Bonjour, bienvenue dans ce cours...",
    "confidence": 0.85
  },
  {
    "index": 1,
    "text": "...",
    "confidence": 0.45
  }
]
```

### Identifier les transcripts Ã  vÃ©rifier

```python
import json

with open("data/processed/.../transcripts.json", 'r') as f:
    transcripts = json.load(f)

# Trouver les transcripts de faible confidence
low_confidence = [t for t in transcripts if t["confidence"] < 0.6]
print(f"Transcripts Ã  vÃ©rifier: {len(low_confidence)}")
```

## ğŸ”„ Utilisation pour Fine-tuning

Une fois les transcripts gÃ©nÃ©rÃ©s, utilisez directement le dataset pour fine-tuning :

```bash
python scripts/fine_tune_meetings.py \
  --train_data data/processed/MEscriva_french-education-speech_with_transcripts \
  --eval_data data/processed/MEscriva_french-education-speech_with_transcripts \
  --phase 1
```

## ğŸ’¡ StratÃ©gies d'AmÃ©lioration

### 1. AmÃ©liorer la QualitÃ© des Transcripts

**Option A : Utiliser un modÃ¨le plus puissant**
```bash
--model_name openai/whisper-large-v3  # Plus lent mais meilleure qualitÃ©
```

**Option B : Post-processing**
- Corriger les erreurs frÃ©quentes manuellement
- Utiliser un lexique de correction (noms propres, termes spÃ©cialisÃ©s)

### 2. Pseudo-labeling ItÃ©ratif

1. GÃ©nÃ©rer transcripts avec modÃ¨le de base
2. Fine-tuner sur ces transcripts
3. RÃ©gÃ©nÃ©rer transcripts avec modÃ¨le fine-tunÃ©
4. RÃ©pÃ©ter jusqu'Ã  convergence

```bash
# Ã‰tape 1 : GÃ©nÃ©rer avec modÃ¨le de base
python scripts/generate_transcripts.py --dataset_name MEscriva/french-education-speech

# Ã‰tape 2 : Fine-tuner
python scripts/fine_tune_meetings.py \
  --train_data data/processed/.../with_transcripts \
  --phase 1

# Ã‰tape 3 : RÃ©gÃ©nÃ©rer avec modÃ¨le fine-tunÃ©
python scripts/generate_transcripts.py \
  --dataset_name MEscriva/french-education-speech \
  --model_name outputs/models/whisper-meetings-phase1/final
```

### 3. Combinaison avec DonnÃ©es Manuelles

- GÃ©nÃ©rer transcripts automatiques pour la majoritÃ© des donnÃ©es
- Annoter manuellement un sous-ensemble (10-20%) pour validation/qualitÃ©
- MÃ©langer les deux pour fine-tuning

## âš™ï¸ ParamÃ¨tres AvancÃ©s

### Performance

**GPU recommandÃ©** : La transcription est beaucoup plus rapide sur GPU.

```bash
# Forcer CPU (plus lent)
python scripts/generate_transcripts.py \
  --dataset_name MEscriva/french-education-speech \
  --device cpu
```

**Traitement par batch** : Le script traite un Ã©chantillon Ã  la fois (car durÃ©es audio variables), mais sauvegarde pÃ©riodiquement pour Ã©viter la perte en cas d'interruption.

### Gestion MÃ©moire

Pour datasets trÃ¨s volumineux :
- Utiliser `--max_samples` pour traiter par chunks
- Traiter sÃ©parÃ©ment train/validation/test
- Sauvegardes intermÃ©diaires automatiques tous les 100 Ã©chantillons

## ğŸ› Troubleshooting

### Erreur "Colonne audio non trouvÃ©e"

Le script essaie automatiquement `audio`, `path`, `file`. Si votre dataset utilise un autre nom :
- VÃ©rifiez les colonnes : `dataset.column_names`
- Modifiez le script si nÃ©cessaire (section identification colonne audio)

### Erreur "CUDA out of memory"

- RÃ©duire `batch_size` (actuellement 1, donc peu probable)
- Utiliser `--device cpu`
- Traiter par chunks avec `--max_samples`

### Transcripts de mauvaise qualitÃ©

- VÃ©rifier qualitÃ© audio (bruit, dÃ©bit de parole)
- Utiliser modÃ¨le plus puissant (`whisper-large-v3`)
- Filtrer par `--min_confidence` plus Ã©levÃ©
- Post-processing manuel des erreurs frÃ©quentes

## ğŸ“ Exemple Complet

```bash
# 1. GÃ©nÃ©rer transcripts (test avec 50 Ã©chantillons)
python scripts/generate_transcripts.py \
  --dataset_name MEscriva/french-education-speech \
  --split train \
  --max_samples 50 \
  --output_dir data/processed

# 2. VÃ©rifier les rÃ©sultats
cat data/processed/MEscriva_french-education-speech_with_transcripts/transcripts.json | head -20

# 3. Si satisfait, gÃ©nÃ©rer pour tout le dataset
python scripts/generate_transcripts.py \
  --dataset_name MEscriva/french-education-speech \
  --split train \
  --min_confidence 0.6 \
  --output_dir data/processed

# 4. Fine-tuning
python scripts/fine_tune_meetings.py \
  --train_data data/processed/MEscriva_french-education-speech_with_transcripts \
  --eval_data data/processed/MEscriva_french-education-speech_with_transcripts \
  --phase 1
```

## ğŸ“ Bonnes Pratiques

1. **Toujours tester d'abord** avec `--max_samples 10-50`
2. **VÃ©rifier la qualitÃ©** des transcripts gÃ©nÃ©rÃ©s avant de tout traiter
3. **Filtrer par confidence** pour Ã©viter de polluer l'entraÃ®nement
4. **Sauvegarder pÃ©riodiquement** (fait automatiquement)
5. **ItÃ©rer** : gÃ©nÃ©rer â†’ fine-tuner â†’ rÃ©gÃ©nÃ©rer pour amÃ©lioration

---

**Note** : Les transcripts gÃ©nÃ©rÃ©s sont des "pseudo-labels" - ils ne sont pas parfaits mais constituent une excellente base pour le fine-tuning, surtout si combinÃ©s avec quelques donnÃ©es manuellement annotÃ©es.

