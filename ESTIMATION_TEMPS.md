# Estimation Temps d'Entra√Ænement QAT

## ‚è±Ô∏è Temps R√©el (Corrig√©)

### Sur GPU Moderne (A100/V100/RTX 3090)

**Configuration Optimis√©e (Par D√©faut)** :
- Dataset : 60,000 samples (~500h de segments 30s)
- √âpoques : 5
- Batch size : 8
- Gradient accumulation : 4
- **Temps total : 2-4 heures** ‚ö°

**Configuration Extended** :
- Dataset : 120,000 samples (~1000h)
- √âpoques : 10
- Batch size : 8
- **Temps total : 6-10 heures**

### Sur CPU

- **Temps total : 1-2 jours** (beaucoup plus lent, pas recommand√©)

## üìä D√©tails du Calcul

### Pourquoi c'est si rapide ?

1. **Mod√®le pr√©-entra√Æn√©** : On part de v0.2, pas depuis z√©ro
2. **Moins d'√©poques** : 5 vs 160 pour entra√Ænement initial
3. **Sous-ensemble dataset** : 500h vs 10,000h pour entra√Ænement initial
4. **Mod√®le distill√© rapide** : ~0.1x RTF en inference, ~0.3-0.5x RTF en training

### Calcul D√©taill√©

```
Dataset: 60,000 segments √ó 30s = 500h audio
Effective batch: 8 √ó 4 = 32
Steps par epoch: 60,000 / 32 = 1,875 steps
Temps par step: ~0.5-1s (GPU moderne)
Temps par epoch: 1,875 √ó 0.75s = ~23 minutes
Total (5 epochs): ~2 heures
```

*(+ overhead I/O, validation, etc. = 2-4h total)*

## üéØ Recommandation

**Utilisez les param√®tres par d√©faut** (optimis√©s) :
- ‚úÖ 2-4h de training (rapide)
- ‚úÖ Qualit√© excellente (suffisant pour publication)
- ‚úÖ Peut toujours √©tendre ensuite si besoin

## üîß Ajustements Possibles

Si vous avez plus de temps GPU disponible :

```bash
# Version extended (6-10h) - Qualit√© maximale
python scripts/train_qat.py \
  --num_epochs 10 \
  --max_samples 120000
```

Si GPU limit√© :

```bash
# Version rapide (1-2h) - Minimum viable
python scripts/train_qat.py \
  --num_epochs 3 \
  --max_samples 30000 \
  --per_device_batch_size 4
```

