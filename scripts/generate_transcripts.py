#!/usr/bin/env python3
"""
Script pour gÃ©nÃ©rer automatiquement les transcripts d'un dataset audio sans transcripts.
Utilise Whisper pour crÃ©er des pseudo-labels (transcriptions automatiques).
"""

import argparse
import json
from pathlib import Path
from tqdm import tqdm
import torch
from transformers import WhisperProcessor, WhisperForConditionalGeneration
from datasets import load_dataset, Dataset, DatasetDict
import librosa
import numpy as np

import sys
sys.path.append(str(Path(__file__).parent.parent))


class AutoTranscriptGenerator:
    """GÃ©nÃ©rateur de transcripts automatiques avec Whisper."""
    
    def __init__(
        self,
        model_name: str = "bofenghuang/whisper-large-v3-distil-fr-v0.2",
        device: str = None,
        batch_size: int = 1,
    ):
        """
        Args:
            model_name: Nom du modÃ¨le Whisper Ã  utiliser
            device: Device (cuda/cpu), auto-dÃ©tectÃ© si None
            batch_size: Taille de batch (1 par dÃ©faut, car audio peut varier)
        """
        self.model_name = model_name
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.batch_size = batch_size
        
        print(f"Chargement du modÃ¨le {model_name}...")
        self.processor = WhisperProcessor.from_pretrained(model_name)
        self.model = WhisperForConditionalGeneration.from_pretrained(model_name)
        self.model = self.model.to(self.device)
        self.model.eval()
        
        print(f"âœ… ModÃ¨le chargÃ© sur {self.device}")
    
    def transcribe_audio(self, audio_array: np.ndarray, sample_rate: int = 16000) -> dict:
        """
        Transcrit un audio avec Whisper.
        
        Args:
            audio_array: Array audio numpy
            sample_rate: Sample rate
        
        Returns:
            Dict avec 'text' et 'confidence' (si disponible)
        """
        # PrÃ©parer inputs
        inputs = self.processor(
            audio=audio_array,
            sampling_rate=sample_rate,
            return_tensors="pt",
        ).to(self.device)
        
        # GÃ©nÃ©rer transcription
        with torch.no_grad():
            generated_ids = self.model.generate(
                inputs["input_features"],
                max_length=448,
                num_beams=5,
                language="fr",
                task="transcribe",
                return_dict_in_generate=True,
                output_scores=True,
            )
        
        # DÃ©coder
        transcription = self.processor.batch_decode(
            generated_ids.sequences,
            skip_special_tokens=True,
        )[0]
        
        # Calculer confidence approximative depuis les scores
        confidence = None
        if hasattr(generated_ids, 'scores') and generated_ids.scores:
            # Moyenne des log probs (approximation)
            log_probs = []
            for score in generated_ids.scores:
                # Softmax pour obtenir probabilitÃ©s
                probs = torch.softmax(score, dim=-1)
                # ProbabilitÃ© du token choisi
                max_probs = torch.max(probs, dim=-1)[0]
                log_probs.append(max_probs.mean().item())
            
            if log_probs:
                # Moyenne des confidences par token
                confidence = np.mean(log_probs)
        
        return {
            "text": transcription,
            "confidence": confidence,
        }
    
    def transcribe_dataset(
        self,
        dataset,
        audio_column: str = "audio",
        sample_rate: int = 16000,
        max_samples: int = None,
        min_confidence: float = None,
        save_intermediate: bool = True,
        output_path: str = None,
    ) -> Dataset:
        """
        Transcrit tous les audios d'un dataset.
        
        Args:
            dataset: Dataset HuggingFace avec colonne audio
            audio_column: Nom de la colonne audio
            sample_rate: Sample rate cible
            max_samples: Limiter nombre d'Ã©chantillons (pour test)
            min_confidence: Filtrer par confidence minimale (optionnel)
            save_intermediate: Sauvegarder pÃ©riodiquement
            output_path: Chemin pour sauvegarder rÃ©sultats intermÃ©diaires
        
        Returns:
            Dataset avec colonne 'text' ajoutÃ©e
        """
        print(f"Transcription de {len(dataset)} Ã©chantillons...")
        
        transcripts = []
        confidences = []
        failed_indices = []
        
        # Limiter si demandÃ©
        dataset_to_process = dataset
        if max_samples and len(dataset) > max_samples:
            dataset_to_process = dataset.select(range(max_samples))
            print(f"  LimitÃ© Ã  {max_samples} Ã©chantillons pour test")
        
        # Traiter chaque Ã©chantillon
        for idx, example in enumerate(tqdm(dataset_to_process, desc="Transcription")):
            try:
                # Extraire audio
                audio_data = example[audio_column]
                
                if audio_data is None:
                    print(f"  âš ï¸  Ã‰chantillon {idx}: audio manquant")
                    transcripts.append("")
                    confidences.append(0.0)
                    failed_indices.append(idx)
                    continue
                
                # Charger audio si nÃ©cessaire
                if isinstance(audio_data, dict):
                    audio_array = audio_data["array"]
                    sr = audio_data.get("sampling_rate", sample_rate)
                elif isinstance(audio_data, str):
                    # Chemin vers fichier
                    audio_array, sr = librosa.load(audio_data, sr=sample_rate)
                else:
                    audio_array = audio_data
                    sr = sample_rate
                
                # Resample si nÃ©cessaire
                if sr != sample_rate:
                    audio_array = librosa.resample(
                        audio_array.astype(np.float32),
                        orig_sr=sr,
                        target_sr=sample_rate,
                    )
                
                # Normaliser
                if np.max(np.abs(audio_array)) > 0:
                    audio_array = audio_array / np.max(np.abs(audio_array))
                
                # Transcrire
                result = self.transcribe_audio(audio_array, sample_rate)
                
                transcripts.append(result["text"])
                confidences.append(result.get("confidence", 0.0))
                
                # Sauvegarde intermÃ©diaire tous les 100 Ã©chantillons
                if save_intermediate and (idx + 1) % 100 == 0 and output_path:
                    self._save_intermediate(
                        dataset_to_process,
                        transcripts,
                        confidences,
                        idx + 1,
                        output_path,
                    )
                
            except Exception as e:
                print(f"  âŒ Erreur Ã©chantillon {idx}: {e}")
                transcripts.append("")
                confidences.append(0.0)
                failed_indices.append(idx)
        
        # Statistiques
        valid_transcripts = [t for t in transcripts if t]
        avg_confidence = np.mean([c for c in confidences if c > 0]) if confidences else 0.0
        
        print(f"\nğŸ“Š Statistiques:")
        print(f"  Total: {len(transcripts)}")
        print(f"  RÃ©ussis: {len(valid_transcripts)}")
        print(f"  Ã‰chouÃ©s: {len(failed_indices)}")
        print(f"  Confiance moyenne: {avg_confidence:.3f}")
        
        if failed_indices:
            print(f"  âš ï¸  Indices Ã©chouÃ©s: {failed_indices[:10]}..." if len(failed_indices) > 10 else f"  âš ï¸  Indices Ã©chouÃ©s: {failed_indices}")
        
        # Ajouter colonnes au dataset
        dataset_with_text = dataset_to_process.add_column("text", transcripts)
        dataset_with_text = dataset_with_text.add_column("transcription_confidence", confidences)
        dataset_with_text = dataset_with_text.add_column("auto_generated", [True] * len(transcripts))
        
        # Filtrer par confidence si demandÃ©
        if min_confidence:
            before_filter = len(dataset_with_text)
            dataset_with_text = dataset_with_text.filter(
                lambda x: x["transcription_confidence"] >= min_confidence
            )
            print(f"  FiltrÃ© (confidence >= {min_confidence}): {before_filter} â†’ {len(dataset_with_text)}")
        
        return dataset_with_text
    
    def _save_intermediate(
        self,
        dataset,
        transcripts,
        confidences,
        num_processed,
        output_path,
    ):
        """Sauvegarde intermÃ©diaire."""
        try:
            temp_dataset = dataset.select(range(num_processed))
            temp_dataset = temp_dataset.add_column("text", transcripts[:num_processed])
            temp_dataset = temp_dataset.add_column("transcription_confidence", confidences[:num_processed])
            
            temp_path = Path(output_path) / f"intermediate_{num_processed}"
            temp_dataset.save_to_disk(str(temp_path))
        except Exception as e:
            print(f"  âš ï¸  Impossible de sauvegarder intermÃ©diaire: {e}")


def main():
    parser = argparse.ArgumentParser(
        description="GÃ©nÃ©rer automatiquement les transcripts d'un dataset audio"
    )
    parser.add_argument(
        "--dataset_name",
        type=str,
        default="MEscriva/french-education-speech",
        help="Nom du dataset HuggingFace",
    )
    parser.add_argument(
        "--split",
        type=str,
        default="train",
        help="Split du dataset Ã  traiter",
    )
    parser.add_argument(
        "--model_name",
        type=str,
        default="bofenghuang/whisper-large-v3-distil-fr-v0.2",
        help="ModÃ¨le Whisper Ã  utiliser",
    )
    parser.add_argument(
        "--output_dir",
        type=str,
        default="data/processed",
        help="RÃ©pertoire de sortie",
    )
    parser.add_argument(
        "--output_name",
        type=str,
        default=None,
        help="Nom du dataset de sortie (dÃ©faut: {dataset_name}_with_transcripts)",
    )
    parser.add_argument(
        "--max_samples",
        type=int,
        default=None,
        help="Nombre max d'Ã©chantillons (pour test rapide)",
    )
    parser.add_argument(
        "--min_confidence",
        type=float,
        default=None,
        help="Confidence minimale pour garder transcript (0-1)",
    )
    parser.add_argument(
        "--device",
        type=str,
        default=None,
        help="Device (cuda/cpu), auto si None",
    )
    parser.add_argument(
        "--push_to_hub",
        action="store_true",
        help="Pousser le dataset sur HuggingFace Hub",
    )
    parser.add_argument(
        "--hub_token",
        type=str,
        default=None,
        help="Token HuggingFace (ou variable env HF_TOKEN)",
    )
    
    args = parser.parse_args()
    
    # Charger dataset
    print(f"ğŸ“¥ Chargement du dataset {args.dataset_name}...")
    try:
        dataset = load_dataset(args.dataset_name, split=args.split)
    except Exception as e:
        print(f"âŒ Erreur lors du chargement: {e}")
        print("ğŸ’¡ Essayez avec --split train ou vÃ©rifiez le nom du dataset")
        return
    
    print(f"âœ… Dataset chargÃ©: {len(dataset)} Ã©chantillons")
    
    # VÃ©rifier colonnes
    print(f"   Colonnes: {dataset.column_names}")
    
    # Identifier colonne audio
    audio_column = None
    for col in ["audio", "path", "file"]:
        if col in dataset.column_names:
            audio_column = col
            break
    
    if not audio_column:
        print("âš ï¸  Colonne audio non trouvÃ©e, tentative avec 'audio'...")
        audio_column = "audio"
    
    print(f"   Colonne audio utilisÃ©e: {audio_column}")
    
    # CrÃ©er gÃ©nÃ©rateur
    generator = AutoTranscriptGenerator(
        model_name=args.model_name,
        device=args.device,
    )
    
    # Nom de sortie
    output_name = args.output_name or f"{args.dataset_name.replace('/', '_')}_with_transcripts"
    output_path = Path(args.output_dir) / output_name
    output_path.mkdir(parents=True, exist_ok=True)
    
    # GÃ©nÃ©rer transcripts
    print(f"\nğŸ™ï¸  GÃ©nÃ©ration des transcripts...")
    dataset_with_transcripts = generator.transcribe_dataset(
        dataset,
        audio_column=audio_column,
        max_samples=args.max_samples,
        min_confidence=args.min_confidence,
        save_intermediate=True,
        output_path=str(output_path),
    )
    
    # Sauvegarder
    print(f"\nğŸ’¾ Sauvegarde dans {output_path}...")
    
    # Si dataset avait plusieurs splits, crÃ©er DatasetDict
    try:
        full_dataset = load_dataset(args.dataset_name)
        if isinstance(full_dataset, DatasetDict):
            # Mettre Ã  jour le split traitÃ©
            full_dataset[args.split] = dataset_with_transcripts
            full_dataset.save_to_disk(str(output_path))
        else:
            dataset_with_transcripts.save_to_disk(str(output_path))
    except:
        dataset_with_transcripts.save_to_disk(str(output_path))
    
    print(f"âœ… Dataset sauvegardÃ© dans {output_path}")
    
    # Exporter aussi en JSON pour rÃ©fÃ©rence
    json_path = output_path / "transcripts.json"
    transcripts_list = [
        {
            "index": i,
            "text": dataset_with_transcripts[i]["text"],
            "confidence": dataset_with_transcripts[i].get("transcription_confidence", 0.0),
        }
        for i in range(len(dataset_with_transcripts))
    ]
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(transcripts_list, f, indent=2, ensure_ascii=False)
    print(f"âœ… Transcripts JSON sauvegardÃ©s dans {json_path}")
    
    # Pousser sur Hub si demandÃ©
    if args.push_to_hub:
        print(f"\nğŸš€ Pousse vers HuggingFace Hub...")
        try:
            token = args.hub_token or os.getenv("HF_TOKEN")
            if not token:
                print("âš ï¸  Token HuggingFace non fourni, skip push_to_hub")
            else:
                dataset_with_transcripts.push_to_hub(
                    output_name,
                    token=token,
                )
                print(f"âœ… Dataset poussÃ© sur Hub: {output_name}")
        except Exception as e:
            print(f"âŒ Erreur lors du push: {e}")
    
    print(f"\n{'='*60}")
    print("âœ… GÃ‰NÃ‰RATION TERMINÃ‰E")
    print(f"{'='*60}")
    print(f"\nğŸ“ Dataset avec transcripts: {output_path}")
    print(f"\nğŸ’¡ Pour utiliser ce dataset pour fine-tuning:")
    print(f"   python scripts/fine_tune_meetings.py \\")
    print(f"     --train_data {output_path} \\")
    print(f"     --eval_data {output_path} \\")
    print(f"     --phase 1")


if __name__ == "__main__":
    import os
    main()

