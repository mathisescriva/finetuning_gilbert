# D√©ploiement sur HuggingFace

## üöÄ D√©ployer le mod√®le ONNX Gilbert

### Pr√©requis

1. **Token HuggingFace** :
   ```bash
   # Option 1: Variable d'environnement
   export HUGGINGFACE_TOKEN="hf_xxxxx"
   
   # Option 2: Login HuggingFace CLI
   huggingface-cli login
   ```

2. **Installation d√©pendances** :
   ```bash
   pip install huggingface_hub
   ```

### D√©ploiement

```bash
# D√©ployer avec nom personnalis√©
python scripts/deploy_to_hf.py \
  --repo_name "mathisescriva/gilbert-whisper-onnx" \
  --local_path "outputs/models/gilbert-whisper-ptq-int8/onnx"

# Si repo priv√©
python scripts/deploy_to_hf.py \
  --repo_name "mathisescriva/gilbert-whisper-onnx" \
  --private \
  --token "hf_xxxxx"
```

### Suggestions de noms

- `mathisescriva/gilbert-whisper-onnx`
- `mathisescriva/gilbert-stt-onnx`
- `mathisescriva/gilbert-whisper-fr-onnx`
- `mathisescriva/gilbert-whisper-optimized`

### V√©rification

Apr√®s d√©ploiement, v√©rifier sur :
- https://huggingface.co/votre-username/gilbert-whisper-onnx

### Utilisation depuis HuggingFace

```python
from optimum.onnxruntime import ORTModelForSpeechSeq2Seq
from transformers import AutoProcessor

model = ORTModelForSpeechSeq2Seq.from_pretrained("votre-username/gilbert-whisper-onnx")
processor = AutoProcessor.from_pretrained("votre-username/gilbert-whisper-onnx")
```

